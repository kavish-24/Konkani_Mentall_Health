{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1GEX2rW4XBoPv3A4rzLo4VjeL8tXOT7p7",
      "authorship_tag": "ABX9TyMLE4PVKsy9R9BlUUVKkN94",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavish-24/Konkani_Mental_Health/blob/main/AudioHandling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTr2sjFwSr4D",
        "outputId": "6e1d0223-9f25-4859-cdf6-105fa16e7b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=bfbe9a6157a9f174678d7817712b79e56dbae37cc7f5aa2d7a1faacf22849038\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKGjo0YJVeTz",
        "outputId": "d6600b0a-b4d9-479d-b580-776901faf93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s3EY1PreRS-z",
        "outputId": "29b4d301-7436-4da3-c20e-f5fa17b82a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper model once...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 37.3MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Konk Prime News_040517.wav...\n",
            "Loading Whisper model...\n",
            "Transcribing /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/May 2017 (1)/Konk Prime News_040517.wav...\n",
            "Loading audio file...\n",
            "\n",
            "Creating 21 segments...\n",
            "Segment 1: 24.76s (0.00s - 24.76s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_001.mp3\n",
            "Segment 2: 24.74s (24.76s - 49.50s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_002.mp3\n",
            "Segment 3: 24.96s (49.50s - 74.46s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_003.mp3\n",
            "Segment 4: 24.48s (74.46s - 98.94s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_004.mp3\n",
            "Segment 5: 24.76s (98.94s - 123.70s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_005.mp3\n",
            "Segment 6: 19.82s (123.70s - 143.52s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_006.mp3\n",
            "Segment 7: 30.00s (143.52s - 173.52s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_007.mp3\n",
            "Segment 8: 24.36s (173.52s - 197.88s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_008.mp3\n",
            "Segment 9: 24.20s (197.88s - 222.08s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_009.mp3\n",
            "Segment 10: 24.98s (222.08s - 247.06s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_010.mp3\n",
            "Segment 11: 24.94s (247.06s - 272.00s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_011.mp3\n",
            "Segment 12: 16.48s (272.00s - 288.48s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_012.mp3\n",
            "Segment 13: 24.46s (288.48s - 312.94s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_013.mp3\n",
            "Segment 14: 24.80s (312.94s - 337.74s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_014.mp3\n",
            "Segment 15: 24.62s (337.74s - 362.36s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_015.mp3\n",
            "Segment 16: 24.66s (362.36s - 387.02s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_016.mp3\n",
            "Segment 17: 24.82s (387.02s - 411.84s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_017.mp3\n",
            "Segment 18: 24.36s (411.84s - 436.20s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_018.mp3\n",
            "Segment 19: 24.52s (436.20s - 460.72s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_019.mp3\n",
            "Segment 20: 24.40s (460.72s - 485.12s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_020.mp3\n",
            "Segment 21: 18.46s (485.12s - 503.58s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517/Konk Prime News_040517_segment_021.mp3\n",
            "\n",
            "Done! Created 21 segments in '/content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_040517' directory\n",
            "\n",
            "Processing Konk Prime_010517.wav...\n",
            "Loading Whisper model...\n",
            "Transcribing /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/May 2017 (1)/Konk Prime_010517.wav...\n",
            "Loading audio file...\n",
            "\n",
            "Creating 18 segments...\n",
            "Segment 1: 24.66s (0.00s - 24.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_001.mp3\n",
            "Segment 2: 22.14s (24.66s - 46.80s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_002.mp3\n",
            "Segment 3: 19.58s (46.80s - 66.38s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_003.mp3\n",
            "Segment 4: 24.96s (66.38s - 91.34s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_004.mp3\n",
            "Segment 5: 24.64s (91.34s - 115.98s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_005.mp3\n",
            "Segment 6: 24.80s (115.98s - 140.78s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_006.mp3\n",
            "Segment 7: 24.10s (140.78s - 164.88s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_007.mp3\n",
            "Segment 8: 8.28s (164.88s - 173.16s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_008.mp3\n",
            "Segment 9: 30.50s (173.16s - 203.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_009.mp3\n",
            "Segment 10: 22.66s (203.66s - 226.32s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_010.mp3\n",
            "Segment 11: 24.80s (226.32s - 251.12s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_011.mp3\n",
            "Segment 12: 24.80s (251.12s - 275.92s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_012.mp3\n",
            "Segment 13: 24.74s (275.92s - 300.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_013.mp3\n",
            "Segment 14: 23.20s (300.66s - 323.86s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_014.mp3\n",
            "Segment 15: 21.44s (323.86s - 345.30s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_015.mp3\n",
            "Segment 16: 24.66s (345.30s - 369.96s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_016.mp3\n",
            "Segment 17: 24.92s (369.96s - 394.88s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_017.mp3\n",
            "Segment 18: 6.12s (394.88s - 401.00s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517/Konk Prime_010517_segment_018.mp3\n",
            "\n",
            "Done! Created 18 segments in '/content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime_010517' directory\n",
            "\n",
            "Processing Konk Prime News_220517.wav...\n",
            "Loading Whisper model...\n",
            "Transcribing /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/May 2017 (1)/Konk Prime News_220517.wav...\n",
            "Loading audio file...\n",
            "\n",
            "Creating 19 segments...\n",
            "Segment 1: 24.98s (0.00s - 24.98s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_001.mp3\n",
            "Segment 2: 20.30s (24.98s - 45.28s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_002.mp3\n",
            "Segment 3: 24.40s (45.28s - 69.68s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_003.mp3\n",
            "Segment 4: 24.98s (69.68s - 94.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_004.mp3\n",
            "Segment 5: 19.04s (94.66s - 113.70s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_005.mp3\n",
            "Segment 6: 24.68s (113.70s - 138.38s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_006.mp3\n",
            "Segment 7: 24.86s (138.38s - 163.24s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_007.mp3\n",
            "Segment 8: 24.44s (163.24s - 187.68s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_008.mp3\n",
            "Segment 9: 24.04s (187.68s - 211.72s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_009.mp3\n",
            "Segment 10: 24.86s (211.72s - 236.58s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_010.mp3\n",
            "Segment 11: 24.94s (236.58s - 261.52s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_011.mp3\n",
            "Segment 12: 24.08s (261.52s - 285.60s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_012.mp3\n",
            "Segment 13: 24.58s (285.60s - 310.18s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_013.mp3\n",
            "Segment 14: 22.82s (310.18s - 333.00s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_014.mp3\n",
            "Segment 15: 24.48s (333.00s - 357.48s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_015.mp3\n",
            "Segment 16: 24.90s (357.48s - 382.38s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_016.mp3\n",
            "Segment 17: 14.94s (382.38s - 397.32s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_017.mp3\n",
            "Segment 18: 24.66s (397.32s - 421.98s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_018.mp3\n",
            "Segment 19: 23.68s (421.98s - 445.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517/Konk Prime News_220517_segment_019.mp3\n",
            "\n",
            "Done! Created 19 segments in '/content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_220517' directory\n",
            "\n",
            "Processing Konkani Prime News_080517.wav...\n",
            "Loading Whisper model...\n",
            "Transcribing /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/May 2017 (1)/Konkani Prime News_080517.wav...\n",
            "Loading audio file...\n",
            "\n",
            "Creating 19 segments...\n",
            "Segment 1: 24.90s (0.00s - 24.90s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_001.mp3\n",
            "Segment 2: 24.34s (24.90s - 49.24s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_002.mp3\n",
            "Segment 3: 24.80s (49.24s - 74.04s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_003.mp3\n",
            "Segment 4: 24.62s (74.04s - 98.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_004.mp3\n",
            "Segment 5: 24.64s (98.66s - 123.30s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_005.mp3\n",
            "Segment 6: 24.84s (123.30s - 148.14s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_006.mp3\n",
            "Segment 7: 24.94s (148.14s - 173.08s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_007.mp3\n",
            "Segment 8: 24.68s (173.08s - 197.76s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_008.mp3\n",
            "Segment 9: 24.72s (197.76s - 222.48s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_009.mp3\n",
            "Segment 10: 23.02s (222.48s - 245.50s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_010.mp3\n",
            "Segment 11: 24.88s (245.50s - 270.38s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_011.mp3\n",
            "Segment 12: 24.78s (270.38s - 295.16s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_012.mp3\n",
            "Segment 13: 24.88s (295.16s - 320.04s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_013.mp3\n",
            "Segment 14: 24.98s (320.04s - 345.02s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_014.mp3\n",
            "Segment 15: 24.70s (345.02s - 369.72s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_015.mp3\n",
            "Segment 16: 24.64s (369.72s - 394.36s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_016.mp3\n",
            "Segment 17: 24.94s (394.36s - 419.30s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_017.mp3\n",
            "Segment 18: 24.92s (419.30s - 444.22s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_018.mp3\n",
            "Segment 19: 20.50s (444.22s - 464.72s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517/Konkani Prime News_080517_segment_019.mp3\n",
            "\n",
            "Done! Created 19 segments in '/content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_080517' directory\n",
            "\n",
            "Processing Konkani Prime News_150517.wav...\n",
            "Loading Whisper model...\n",
            "Transcribing /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/May 2017 (1)/Konkani Prime News_150517.wav...\n",
            "Loading audio file...\n",
            "\n",
            "Creating 18 segments...\n",
            "Segment 1: 24.98s (0.00s - 24.98s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_001.mp3\n",
            "Segment 2: 24.78s (24.98s - 49.76s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_002.mp3\n",
            "Segment 3: 22.92s (49.76s - 72.68s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_003.mp3\n",
            "Segment 4: 18.60s (72.68s - 91.28s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_004.mp3\n",
            "Segment 5: 9.56s (91.28s - 100.84s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_005.mp3\n",
            "Segment 6: 31.28s (100.84s - 132.12s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_006.mp3\n",
            "Segment 7: 24.88s (132.12s - 157.00s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_007.mp3\n",
            "Segment 8: 24.82s (157.00s - 181.82s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_008.mp3\n",
            "Segment 9: 24.78s (181.82s - 206.60s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_009.mp3\n",
            "Segment 10: 24.84s (206.60s - 231.44s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_010.mp3\n",
            "Segment 11: 24.16s (231.44s - 255.60s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_011.mp3\n",
            "Segment 12: 24.94s (255.60s - 280.54s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_012.mp3\n",
            "Segment 13: 23.12s (280.54s - 303.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_013.mp3\n",
            "Segment 14: 23.98s (303.66s - 327.64s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_014.mp3\n",
            "Segment 15: 24.80s (327.64s - 352.44s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_015.mp3\n",
            "Segment 16: 24.92s (352.44s - 377.36s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_016.mp3\n",
            "Segment 17: 19.92s (377.36s - 397.28s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_017.mp3\n",
            "Segment 18: 5.42s (397.28s - 402.70s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517/Konkani Prime News_150517_segment_018.mp3\n",
            "\n",
            "Done! Created 18 segments in '/content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konkani Prime News_150517' directory\n",
            "\n",
            "Processing Konk Prime News_110517.wav...\n",
            "Loading Whisper model...\n",
            "Transcribing /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/May 2017 (1)/Konk Prime News_110517.wav...\n",
            "Loading audio file...\n",
            "\n",
            "Creating 18 segments...\n",
            "Segment 1: 24.66s (0.00s - 24.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_001.mp3\n",
            "Segment 2: 22.74s (24.66s - 47.40s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_002.mp3\n",
            "Segment 3: 16.60s (47.40s - 64.00s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_003.mp3\n",
            "Segment 4: 18.72s (64.00s - 82.72s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_004.mp3\n",
            "Segment 5: 24.02s (82.72s - 106.74s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_005.mp3\n",
            "Segment 6: 24.72s (106.74s - 131.46s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_006.mp3\n",
            "Segment 7: 24.20s (131.46s - 155.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_007.mp3\n",
            "Segment 8: 24.72s (155.66s - 180.38s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_008.mp3\n",
            "Segment 9: 24.48s (180.38s - 204.86s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_009.mp3\n",
            "Segment 10: 24.82s (204.86s - 229.68s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_010.mp3\n",
            "Segment 11: 24.14s (229.68s - 253.82s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_011.mp3\n",
            "Segment 12: 24.26s (253.82s - 278.08s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_012.mp3\n",
            "Segment 13: 24.96s (278.08s - 303.04s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_013.mp3\n",
            "Segment 14: 24.84s (303.04s - 327.88s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_014.mp3\n",
            "Segment 15: 24.52s (327.88s - 352.40s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_015.mp3\n",
            "Segment 16: 24.46s (352.40s - 376.86s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_016.mp3\n",
            "Segment 17: 24.80s (376.86s - 401.66s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_017.mp3\n",
            "Segment 18: 9.66s (401.66s - 411.32s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517/Konk Prime News_110517_segment_018.mp3\n",
            "\n",
            "Done! Created 18 segments in '/content/drive/MyDrive/Anju Project (1)/Audio_segments/May/Konk Prime News_110517' directory\n",
            "\n",
            "Processing konkani prime news_250517.wav...\n",
            "Loading Whisper model...\n",
            "Transcribing /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/May 2017 (1)/konkani prime news_250517.wav...\n",
            "Loading audio file...\n",
            "\n",
            "Creating 17 segments...\n",
            "Segment 1: 24.98s (0.00s - 24.98s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_001.mp3\n",
            "Segment 2: 24.82s (24.98s - 49.80s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_002.mp3\n",
            "Segment 3: 24.84s (49.80s - 74.64s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_003.mp3\n",
            "Segment 4: 24.28s (74.64s - 98.92s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_004.mp3\n",
            "Segment 5: 24.78s (98.92s - 123.70s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_005.mp3\n",
            "Segment 6: 24.82s (123.70s - 148.52s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_006.mp3\n",
            "Segment 7: 24.50s (148.52s - 173.02s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_007.mp3\n",
            "Segment 8: 24.88s (173.02s - 197.90s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_008.mp3\n",
            "Segment 9: 24.92s (197.90s - 222.82s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_009.mp3\n",
            "Segment 10: 24.48s (222.82s - 247.30s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_010.mp3\n",
            "Segment 11: 24.76s (247.30s - 272.06s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_011.mp3\n",
            "Segment 12: 24.96s (272.06s - 297.02s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_012.mp3\n",
            "Segment 13: 24.60s (297.02s - 321.62s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_013.mp3\n",
            "Segment 14: 24.88s (321.62s - 346.50s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_014.mp3\n",
            "Segment 15: 24.82s (346.50s - 371.32s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_015.mp3\n",
            "Segment 16: 24.62s (371.32s - 395.94s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_016.mp3\n",
            "Segment 17: 19.76s (395.94s - 415.70s) -> /content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517/konkani prime news_250517_segment_017.mp3\n",
            "\n",
            "Done! Created 17 segments in '/content/drive/MyDrive/Anju Project (1)/Audio_segments/May/konkani prime news_250517' directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'audio_file' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3771243553.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    199\u001b[0m     )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input audio: {audio_file}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Output directory: {output_directory}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Max segment duration: {max_segment_duration} seconds\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'audio_file' is not defined"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "def split_audio_on_word_boundaries(audio_path, max_duration=30, output_dir=\"segments\"):\n",
        "    \"\"\"\n",
        "    Split audio into segments of max_duration seconds, ending at word boundaries.\n",
        "\n",
        "    Args:\n",
        "        audio_path: Path to input audio file\n",
        "        max_duration: Maximum segment duration in seconds (default: 30)\n",
        "        output_dir: Directory to save output segments\n",
        "    \"\"\"\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load Whisper model (use 'base' for speed, 'small'/'medium' for accuracy)\n",
        "    print(\"Loading Whisper model...\")\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    # Transcribe audio with word-level timestamps\n",
        "    print(f\"Transcribing {audio_path}...\")\n",
        "    result = model.transcribe(audio_path, word_timestamps=True)\n",
        "\n",
        "    # Load audio file\n",
        "    print(\"Loading audio file...\")\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "    # Extract all words with timestamps\n",
        "    words = []\n",
        "    for segment in result['segments']:\n",
        "        if 'words' in segment:\n",
        "            words.extend(segment['words'])\n",
        "\n",
        "    if not words:\n",
        "        print(\"No words detected in audio!\")\n",
        "        return\n",
        "\n",
        "    # Split into segments\n",
        "    segments = []\n",
        "    current_start = 0\n",
        "    max_duration_ms = max_duration * 1000\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        word_end_ms = word['end'] * 1000\n",
        "\n",
        "        # Check if adding this word would exceed max duration\n",
        "        if word_end_ms - (current_start * 1000) >= max_duration_ms:\n",
        "            # End segment at previous word boundary\n",
        "            if i > 0:\n",
        "                segment_end = words[i-1]['end']\n",
        "                segments.append((current_start, segment_end))\n",
        "                current_start = segment_end\n",
        "            else:\n",
        "                # First word itself exceeds duration, include it anyway\n",
        "                segment_end = word['end']\n",
        "                segments.append((current_start, segment_end))\n",
        "                current_start = segment_end\n",
        "\n",
        "    # Add final segment\n",
        "    if current_start < words[-1]['end']:\n",
        "        segments.append((current_start, words[-1]['end']))\n",
        "\n",
        "    # Export segments\n",
        "    print(f\"\\nCreating {len(segments)} segments...\")\n",
        "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "\n",
        "    for idx, (start, end) in enumerate(segments, 1):\n",
        "        start_ms = int(start * 1000)\n",
        "        end_ms = int(end * 1000)\n",
        "\n",
        "        segment_audio = audio[start_ms:end_ms]\n",
        "        output_path = os.path.join(output_dir, f\"{base_name}_segment_{idx:03d}.mp3\")\n",
        "\n",
        "        segment_audio.export(output_path, format=\"mp3\")\n",
        "        duration = (end - start)\n",
        "        print(f\"Segment {idx}: {duration:.2f}s ({start:.2f}s - {end:.2f}s) -> {output_path}\")\n",
        "\n",
        "    print(f\"\\nDone! Created {len(segments)} segments in '{output_dir}' directory\")\n",
        "    return segments\n",
        "\n",
        "\n",
        "def split_audio_aggressive(audio_path, max_duration=30, output_dir=\"segments\"):\n",
        "    \"\"\"\n",
        "    Alternative approach: More aggressive splitting for very fast speech.\n",
        "    Uses silence detection as fallback if word boundaries are too far apart.\n",
        "    \"\"\"\n",
        "    from pydub.silence import detect_nonsilent\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Loading Whisper model...\")\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    print(f\"Transcribing {audio_path}...\")\n",
        "    result = model.transcribe(audio_path, word_timestamps=True)\n",
        "\n",
        "    print(\"Loading audio file...\")\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "    # Extract words with timestamps\n",
        "    words = []\n",
        "    for segment in result['segments']:\n",
        "        if 'words' in segment:\n",
        "            words.extend(segment['words'])\n",
        "\n",
        "    if not words:\n",
        "        print(\"No words detected! Falling back to silence detection...\")\n",
        "        return split_on_silence_only(audio_path, max_duration, output_dir)\n",
        "\n",
        "    # Detect silence periods (as backup split points)\n",
        "    nonsilent_ranges = detect_nonsilent(audio, min_silence_len=100, silence_thresh=-40)\n",
        "\n",
        "    segments = []\n",
        "    current_start = 0\n",
        "    max_duration_ms = max_duration * 1000\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        word_end_ms = word['end'] * 1000\n",
        "        current_duration = word_end_ms - (current_start * 1000)\n",
        "\n",
        "        if current_duration >= max_duration_ms:\n",
        "            # Try to find a word boundary close to max_duration\n",
        "            target_time = current_start * 1000 + max_duration_ms\n",
        "\n",
        "            # Find nearest word end before target time\n",
        "            best_split = None\n",
        "            for j in range(i, -1, -1):\n",
        "                candidate_end = words[j]['end'] * 1000\n",
        "                if candidate_end <= target_time:\n",
        "                    best_split = words[j]['end']\n",
        "                    break\n",
        "\n",
        "            if best_split:\n",
        "                segments.append((current_start, best_split))\n",
        "                current_start = best_split\n",
        "            else:\n",
        "                # Use current word as split point\n",
        "                segments.append((current_start, word['end']))\n",
        "                current_start = word['end']\n",
        "\n",
        "    # Add final segment\n",
        "    if current_start < words[-1]['end']:\n",
        "        segments.append((current_start, words[-1]['end']))\n",
        "\n",
        "    # Export segments\n",
        "    print(f\"\\nCreating {len(segments)} segments...\")\n",
        "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "\n",
        "    for idx, (start, end) in enumerate(segments, 1):\n",
        "        start_ms = int(start * 1000)\n",
        "        end_ms = int(end * 1000)\n",
        "\n",
        "        segment_audio = audio[start_ms:end_ms]\n",
        "        output_path = os.path.join(output_dir, f\"{base_name}_segment_{idx:03d}.mp3\")\n",
        "\n",
        "        segment_audio.export(output_path, format=\"mp3\")\n",
        "        duration = (end - start)\n",
        "        print(f\"Segment {idx}: {duration:.2f}s -> {output_path}\")\n",
        "\n",
        "    print(f\"\\nDone! Created {len(segments)} segments\")\n",
        "    return segments\n",
        "\n",
        "def process_audio_directory(input_dir, output_base_dir, max_duration=30):\n",
        "    audio_exts = (\".wav\", \".mp3\", \".m4a\", \".flac\")\n",
        "\n",
        "    print(\"Loading Whisper model once...\")\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    for file in os.listdir(input_dir):\n",
        "        if not file.lower().endswith(audio_exts):\n",
        "            continue\n",
        "\n",
        "        audio_path = os.path.join(input_dir, file)\n",
        "        audio_name = os.path.splitext(file)[0]\n",
        "\n",
        "        # Create unique folder for each audio\n",
        "        audio_output_dir = os.path.join(output_base_dir, audio_name)\n",
        "        os.makedirs(audio_output_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"\\nProcessing {file}...\")\n",
        "        split_audio_on_word_boundaries(\n",
        "            audio_path,\n",
        "            max_duration=max_duration,\n",
        "            output_dir=audio_output_dir\n",
        "        )\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    input_audio_folder = r\"/content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/May 2017 (1)\"\n",
        "    output_segments_folder = r\"/content/drive/MyDrive/Anju Project (1)/Audio_segments/May\"\n",
        "    max_segment_duration = 25\n",
        "\n",
        "    process_audio_directory(\n",
        "        input_audio_folder,\n",
        "        output_segments_folder,\n",
        "        max_duration=max_segment_duration\n",
        "    )\n",
        "\n",
        "    print(f\"Input audio: {audio_file}\")\n",
        "    print(f\"Output directory: {output_directory}\")\n",
        "    print(f\"Max segment duration: {max_segment_duration} seconds\\n\")\n",
        "\n",
        "    # Basic splitting (recommended)\n",
        "    segments = split_audio_on_word_boundaries(\n",
        "        audio_file,\n",
        "        max_duration=max_segment_duration,\n",
        "        output_dir=output_directory\n",
        "    )\n",
        "\n",
        "    # Or use aggressive splitting for very fast speech\n",
        "    # segments = split_audio_aggressive(\n",
        "    #     audio_file,\n",
        "    #     max_duration=max_segment_duration,\n",
        "    #     output_dir=output_directory\n",
        "    # )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "\n",
        "def transcribe_mp3_directory(input_dir, output_dir=None, model_size=\"medium\", language=None):\n",
        "    \"\"\"\n",
        "    Transcribe all MP3 files in a directory using Whisper model.\n",
        "    Skips files that already have a transcript in the output directory.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Loading Whisper {model_size} model...\")\n",
        "    model = whisper.load_model(model_size)\n",
        "\n",
        "    input_path = Path(input_dir)\n",
        "    output_path = Path(output_dir) if output_dir else input_path\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    mp3_files = list(input_path.glob(\"*.mp3\"))\n",
        "\n",
        "    if not mp3_files:\n",
        "        print(f\"No MP3 files found in {input_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(mp3_files)} MP3 files to transcribe\")\n",
        "    print(f\"Language setting: {'Auto-detect' if language is None else language}\\n\")\n",
        "\n",
        "    successful = 0\n",
        "    skipped = 0\n",
        "    empty = 0\n",
        "\n",
        "    for i, mp3_file in enumerate(mp3_files, 1):\n",
        "        transcript_file = output_path / f\"{mp3_file.stem}_transcript.txt\"\n",
        "\n",
        "        # ✅ Skip if file already exists\n",
        "        if transcript_file.exists():\n",
        "            print(f\"[{i}/{len(mp3_files)}] Skipping {mp3_file.name} — transcript already exists.\")\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        print(f\"[{i}/{len(mp3_files)}] Transcribing: {mp3_file.name}\")\n",
        "\n",
        "        try:\n",
        "            transcribe_options = {\n",
        "                \"task\": \"transcribe\",\n",
        "                \"fp16\": False,\n",
        "                \"temperature\": 0.0,\n",
        "                \"best_of\": 5,\n",
        "                \"beam_size\": 5,\n",
        "            }\n",
        "\n",
        "            if language:\n",
        "                transcribe_options[\"language\"] = language\n",
        "\n",
        "            result = model.transcribe(str(mp3_file), **transcribe_options)\n",
        "            transcript_text = result[\"text\"].strip()\n",
        "\n",
        "            if not transcript_text:\n",
        "                print(\"⚠ Empty transcript (possibly silent audio)\")\n",
        "                empty += 1\n",
        "            else:\n",
        "                successful += 1\n",
        "                print(f\"✓ Detected language: {result.get('language', 'unknown')}\")\n",
        "                print(f\"  Text preview: {transcript_text[:100]}{'...' if len(transcript_text) > 100 else ''}\")\n",
        "\n",
        "            with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(transcript_text)\n",
        "\n",
        "            print(f\"  Saved to: {transcript_file.name}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error transcribing {mp3_file.name}: {str(e)}\\n\")\n",
        "            continue\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"Transcription complete!\")\n",
        "    print(f\"Successful: {successful} | Empty: {empty} | Skipped: {skipped} | Total: {len(mp3_files)}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "def transcribe_segment_directories(input_base_dir, output_base_dir, model_size=\"medium\", language=None):\n",
        "    \"\"\"\n",
        "    Transcribe MP3 segments inside each audio directory and save transcripts\n",
        "    to matching output directories. Skips already transcribed files.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Loading Whisper {model_size} model...\")\n",
        "    model = whisper.load_model(model_size)\n",
        "\n",
        "    input_base = Path(input_base_dir)\n",
        "    output_base = Path(output_base_dir)\n",
        "    output_base.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for folder in sorted(input_base.iterdir()):\n",
        "        if not folder.is_dir():\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n📂 Processing folder: {folder.name}\")\n",
        "        out_folder = output_base / folder.name\n",
        "        out_folder.mkdir(exist_ok=True)\n",
        "\n",
        "        mp3_files = list(folder.glob(\"*.mp3\"))\n",
        "        if not mp3_files:\n",
        "            print(f\"  ⚠ No MP3 segments in {folder.name}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"  Found {len(mp3_files)} segments\")\n",
        "\n",
        "        successful, skipped = 0, 0\n",
        "\n",
        "        for i, mp3_file in enumerate(mp3_files, 1):\n",
        "            output_txt = out_folder / f\"{mp3_file.stem}.txt\"\n",
        "\n",
        "            # ✅ Skip if already exists\n",
        "            if output_txt.exists():\n",
        "                print(f\"    [{i}/{len(mp3_files)}] Skipping {mp3_file.name} — transcript already exists.\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            print(f\"    [{i}/{len(mp3_files)}] Transcribing {mp3_file.name}\")\n",
        "\n",
        "            try:\n",
        "                options = {\n",
        "                    \"task\": \"transcribe\",\n",
        "                    \"fp16\": False,\n",
        "                    \"temperature\": 0.0,\n",
        "                    \"best_of\": 5,\n",
        "                    \"beam_size\": 5,\n",
        "                }\n",
        "\n",
        "                if language:\n",
        "                    options[\"language\"] = language\n",
        "\n",
        "                result = model.transcribe(str(mp3_file), **options)\n",
        "                text = result[\"text\"].strip()\n",
        "\n",
        "                with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(text)\n",
        "\n",
        "                successful += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"     ❌ Error: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"✅ Finished {folder.name} | Transcribed: {successful}, Skipped: {skipped}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_segments = \"/content/drive/MyDrive/Anju Project (1)/Audio_segments/May\"\n",
        "    output_transcripts = \"/content/drive/MyDrive/Anju Project (1)/Segment transcript/May\"\n",
        "\n",
        "    transcribe_segment_directories(\n",
        "        input_base_dir=input_segments,\n",
        "        output_base_dir=output_transcripts,\n",
        "        model_size=\"large-v2\",\n",
        "        language=\"mr\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RrMnKDwVHh0",
        "outputId": "529859db-4388-4d2a-ced7-5aac93aee95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper large-v2 model...\n",
            "\n",
            "📂 Processing folder: Konk Prime News_040517\n",
            "  Found 21 segments\n",
            "    [1/21] Transcribing Konk Prime News_040517_segment_001.mp3\n",
            "    [2/21] Transcribing Konk Prime News_040517_segment_002.mp3\n",
            "    [3/21] Transcribing Konk Prime News_040517_segment_003.mp3\n",
            "    [4/21] Transcribing Konk Prime News_040517_segment_004.mp3\n",
            "    [5/21] Transcribing Konk Prime News_040517_segment_005.mp3\n",
            "    [6/21] Transcribing Konk Prime News_040517_segment_006.mp3\n",
            "    [7/21] Transcribing Konk Prime News_040517_segment_007.mp3\n",
            "    [8/21] Transcribing Konk Prime News_040517_segment_008.mp3\n",
            "    [9/21] Transcribing Konk Prime News_040517_segment_009.mp3\n",
            "    [10/21] Transcribing Konk Prime News_040517_segment_010.mp3\n",
            "    [11/21] Transcribing Konk Prime News_040517_segment_011.mp3\n",
            "    [12/21] Transcribing Konk Prime News_040517_segment_012.mp3\n",
            "    [13/21] Transcribing Konk Prime News_040517_segment_013.mp3\n",
            "    [14/21] Transcribing Konk Prime News_040517_segment_014.mp3\n",
            "    [15/21] Transcribing Konk Prime News_040517_segment_015.mp3\n",
            "    [16/21] Transcribing Konk Prime News_040517_segment_016.mp3\n",
            "    [17/21] Transcribing Konk Prime News_040517_segment_017.mp3\n",
            "    [18/21] Transcribing Konk Prime News_040517_segment_018.mp3\n",
            "    [19/21] Transcribing Konk Prime News_040517_segment_019.mp3\n",
            "    [20/21] Transcribing Konk Prime News_040517_segment_020.mp3\n",
            "    [21/21] Transcribing Konk Prime News_040517_segment_021.mp3\n",
            "✅ Finished Konk Prime News_040517 | Transcribed: 21, Skipped: 0\n",
            "\n",
            "📂 Processing folder: Konk Prime News_110517\n",
            "  Found 18 segments\n",
            "    [1/18] Transcribing Konk Prime News_110517_segment_001.mp3\n",
            "    [2/18] Transcribing Konk Prime News_110517_segment_002.mp3\n",
            "    [3/18] Transcribing Konk Prime News_110517_segment_003.mp3\n",
            "    [4/18] Transcribing Konk Prime News_110517_segment_004.mp3\n",
            "    [5/18] Transcribing Konk Prime News_110517_segment_005.mp3\n",
            "    [6/18] Transcribing Konk Prime News_110517_segment_006.mp3\n",
            "    [7/18] Transcribing Konk Prime News_110517_segment_007.mp3\n",
            "    [8/18] Transcribing Konk Prime News_110517_segment_008.mp3\n",
            "    [9/18] Transcribing Konk Prime News_110517_segment_009.mp3\n",
            "    [10/18] Transcribing Konk Prime News_110517_segment_010.mp3\n",
            "    [11/18] Transcribing Konk Prime News_110517_segment_011.mp3\n",
            "    [12/18] Transcribing Konk Prime News_110517_segment_012.mp3\n",
            "    [13/18] Transcribing Konk Prime News_110517_segment_013.mp3\n",
            "    [14/18] Transcribing Konk Prime News_110517_segment_014.mp3\n",
            "    [15/18] Transcribing Konk Prime News_110517_segment_015.mp3\n",
            "    [16/18] Transcribing Konk Prime News_110517_segment_016.mp3\n",
            "    [17/18] Transcribing Konk Prime News_110517_segment_017.mp3\n",
            "    [18/18] Transcribing Konk Prime News_110517_segment_018.mp3\n",
            "✅ Finished Konk Prime News_110517 | Transcribed: 18, Skipped: 0\n",
            "\n",
            "📂 Processing folder: Konk Prime News_220517\n",
            "  Found 19 segments\n",
            "    [1/19] Transcribing Konk Prime News_220517_segment_001.mp3\n",
            "    [2/19] Transcribing Konk Prime News_220517_segment_002.mp3\n",
            "    [3/19] Transcribing Konk Prime News_220517_segment_003.mp3\n",
            "    [4/19] Transcribing Konk Prime News_220517_segment_004.mp3\n",
            "    [5/19] Transcribing Konk Prime News_220517_segment_005.mp3\n",
            "    [6/19] Transcribing Konk Prime News_220517_segment_006.mp3\n",
            "    [7/19] Transcribing Konk Prime News_220517_segment_007.mp3\n",
            "    [8/19] Transcribing Konk Prime News_220517_segment_008.mp3\n",
            "    [9/19] Transcribing Konk Prime News_220517_segment_009.mp3\n",
            "    [10/19] Transcribing Konk Prime News_220517_segment_010.mp3\n",
            "    [11/19] Transcribing Konk Prime News_220517_segment_011.mp3\n",
            "    [12/19] Transcribing Konk Prime News_220517_segment_012.mp3\n",
            "    [13/19] Transcribing Konk Prime News_220517_segment_013.mp3\n",
            "    [14/19] Transcribing Konk Prime News_220517_segment_014.mp3\n",
            "    [15/19] Transcribing Konk Prime News_220517_segment_015.mp3\n",
            "    [16/19] Transcribing Konk Prime News_220517_segment_016.mp3\n",
            "    [17/19] Transcribing Konk Prime News_220517_segment_017.mp3\n",
            "    [18/19] Transcribing Konk Prime News_220517_segment_018.mp3\n",
            "    [19/19] Transcribing Konk Prime News_220517_segment_019.mp3\n",
            "✅ Finished Konk Prime News_220517 | Transcribed: 19, Skipped: 0\n",
            "\n",
            "📂 Processing folder: Konk Prime_010517\n",
            "  Found 18 segments\n",
            "    [1/18] Transcribing Konk Prime_010517_segment_001.mp3\n",
            "    [2/18] Transcribing Konk Prime_010517_segment_002.mp3\n",
            "    [3/18] Transcribing Konk Prime_010517_segment_003.mp3\n",
            "    [4/18] Transcribing Konk Prime_010517_segment_004.mp3\n",
            "    [5/18] Transcribing Konk Prime_010517_segment_005.mp3\n",
            "    [6/18] Transcribing Konk Prime_010517_segment_006.mp3\n",
            "    [7/18] Transcribing Konk Prime_010517_segment_007.mp3\n",
            "    [8/18] Transcribing Konk Prime_010517_segment_008.mp3\n",
            "    [9/18] Transcribing Konk Prime_010517_segment_009.mp3\n",
            "    [10/18] Transcribing Konk Prime_010517_segment_010.mp3\n",
            "    [11/18] Transcribing Konk Prime_010517_segment_011.mp3\n",
            "    [12/18] Transcribing Konk Prime_010517_segment_012.mp3\n",
            "    [13/18] Transcribing Konk Prime_010517_segment_013.mp3\n",
            "    [14/18] Transcribing Konk Prime_010517_segment_014.mp3\n",
            "    [15/18] Transcribing Konk Prime_010517_segment_015.mp3\n",
            "    [16/18] Transcribing Konk Prime_010517_segment_016.mp3\n",
            "    [17/18] Transcribing Konk Prime_010517_segment_017.mp3\n",
            "    [18/18] Transcribing Konk Prime_010517_segment_018.mp3\n",
            "✅ Finished Konk Prime_010517 | Transcribed: 18, Skipped: 0\n",
            "\n",
            "📂 Processing folder: Konkani Prime News_080517\n",
            "  Found 19 segments\n",
            "    [1/19] Transcribing Konkani Prime News_080517_segment_001.mp3\n",
            "    [2/19] Transcribing Konkani Prime News_080517_segment_002.mp3\n",
            "    [3/19] Transcribing Konkani Prime News_080517_segment_003.mp3\n",
            "    [4/19] Transcribing Konkani Prime News_080517_segment_004.mp3\n",
            "    [5/19] Transcribing Konkani Prime News_080517_segment_005.mp3\n",
            "    [6/19] Transcribing Konkani Prime News_080517_segment_006.mp3\n",
            "    [7/19] Transcribing Konkani Prime News_080517_segment_007.mp3\n",
            "    [8/19] Transcribing Konkani Prime News_080517_segment_008.mp3\n",
            "    [9/19] Transcribing Konkani Prime News_080517_segment_009.mp3\n",
            "    [10/19] Transcribing Konkani Prime News_080517_segment_010.mp3\n",
            "    [11/19] Transcribing Konkani Prime News_080517_segment_011.mp3\n",
            "    [12/19] Transcribing Konkani Prime News_080517_segment_012.mp3\n",
            "    [13/19] Transcribing Konkani Prime News_080517_segment_013.mp3\n",
            "    [14/19] Transcribing Konkani Prime News_080517_segment_014.mp3\n",
            "    [15/19] Transcribing Konkani Prime News_080517_segment_015.mp3\n",
            "    [16/19] Transcribing Konkani Prime News_080517_segment_016.mp3\n",
            "    [17/19] Transcribing Konkani Prime News_080517_segment_017.mp3\n",
            "    [18/19] Transcribing Konkani Prime News_080517_segment_018.mp3\n",
            "    [19/19] Transcribing Konkani Prime News_080517_segment_019.mp3\n",
            "✅ Finished Konkani Prime News_080517 | Transcribed: 19, Skipped: 0\n",
            "\n",
            "📂 Processing folder: Konkani Prime News_150517\n",
            "  Found 18 segments\n",
            "    [1/18] Transcribing Konkani Prime News_150517_segment_001.mp3\n",
            "    [2/18] Transcribing Konkani Prime News_150517_segment_002.mp3\n",
            "    [3/18] Transcribing Konkani Prime News_150517_segment_003.mp3\n",
            "    [4/18] Transcribing Konkani Prime News_150517_segment_004.mp3\n",
            "    [5/18] Transcribing Konkani Prime News_150517_segment_005.mp3\n",
            "    [6/18] Transcribing Konkani Prime News_150517_segment_006.mp3\n",
            "    [7/18] Transcribing Konkani Prime News_150517_segment_007.mp3\n",
            "    [8/18] Transcribing Konkani Prime News_150517_segment_008.mp3\n",
            "    [9/18] Transcribing Konkani Prime News_150517_segment_009.mp3\n"
          ]
        }
      ]
    }
  ]
}