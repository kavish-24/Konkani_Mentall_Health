{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1GEX2rW4XBoPv3A4rzLo4VjeL8tXOT7p7",
      "authorship_tag": "ABX9TyPjk9VK0kza2ApWLfpRiDZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavish-24/Konkani_Mentall_Health/blob/main/AudioHandling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTr2sjFwSr4D",
        "outputId": "a8e86456-bd06-4eb1-d8e8-0d3d669f02bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m553.0/803.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=0d1d7c2b00514abd1176042947dbcb2327a663c71ebfd0ece18646e43e6c44f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKGjo0YJVeTz",
        "outputId": "0b86c55b-c80c-4507-ebc4-0918f159cfc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=b762e624668be70d6834a57a55083c2a7874c72c01aa845f2d42daa25ca6be90\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3EY1PreRS-z",
        "outputId": "973d35b6-d374-47ac-fed4-0409846f15ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input audio: /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/August 2017 (1)/Konkani Prime News_100817.wav\n",
            "Output directory: /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug\n",
            "Max segment duration: 30 seconds\n",
            "\n",
            "Loading Whisper model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 49.0MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/August 2017 (1)/Konkani Prime News_100817.wav...\n",
            "Loading audio file...\n",
            "\n",
            "Creating 15 segments...\n",
            "Segment 1: 29.64s (0.00s - 29.64s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_001.mp3\n",
            "Segment 2: 29.40s (29.64s - 59.04s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_002.mp3\n",
            "Segment 3: 29.78s (59.04s - 88.82s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_003.mp3\n",
            "Segment 4: 29.68s (88.82s - 118.50s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_004.mp3\n",
            "Segment 5: 29.38s (118.50s - 147.88s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_005.mp3\n",
            "Segment 6: 29.90s (147.88s - 177.78s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_006.mp3\n",
            "Segment 7: 29.76s (177.78s - 207.54s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_007.mp3\n",
            "Segment 8: 29.14s (207.54s - 236.68s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_008.mp3\n",
            "Segment 9: 18.52s (236.68s - 255.20s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_009.mp3\n",
            "Segment 10: 32.78s (255.20s - 287.98s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_010.mp3\n",
            "Segment 11: 29.66s (287.98s - 317.64s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_011.mp3\n",
            "Segment 12: 29.94s (317.64s - 347.58s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_012.mp3\n",
            "Segment 13: 29.98s (347.58s - 377.56s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_013.mp3\n",
            "Segment 14: 29.58s (377.56s - 407.14s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_014.mp3\n",
            "Segment 15: 7.04s (407.14s - 414.18s) -> /content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug/Konkani Prime News_100817_segment_015.mp3\n",
            "\n",
            "Done! Created 15 segments in '/content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug' directory\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "def split_audio_on_word_boundaries(audio_path, max_duration=30, output_dir=\"segments\"):\n",
        "    \"\"\"\n",
        "    Split audio into segments of max_duration seconds, ending at word boundaries.\n",
        "\n",
        "    Args:\n",
        "        audio_path: Path to input audio file\n",
        "        max_duration: Maximum segment duration in seconds (default: 30)\n",
        "        output_dir: Directory to save output segments\n",
        "    \"\"\"\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load Whisper model (use 'base' for speed, 'small'/'medium' for accuracy)\n",
        "    print(\"Loading Whisper model...\")\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    # Transcribe audio with word-level timestamps\n",
        "    print(f\"Transcribing {audio_path}...\")\n",
        "    result = model.transcribe(audio_path, word_timestamps=True)\n",
        "\n",
        "    # Load audio file\n",
        "    print(\"Loading audio file...\")\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "    # Extract all words with timestamps\n",
        "    words = []\n",
        "    for segment in result['segments']:\n",
        "        if 'words' in segment:\n",
        "            words.extend(segment['words'])\n",
        "\n",
        "    if not words:\n",
        "        print(\"No words detected in audio!\")\n",
        "        return\n",
        "\n",
        "    # Split into segments\n",
        "    segments = []\n",
        "    current_start = 0\n",
        "    max_duration_ms = max_duration * 1000\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        word_end_ms = word['end'] * 1000\n",
        "\n",
        "        # Check if adding this word would exceed max duration\n",
        "        if word_end_ms - (current_start * 1000) >= max_duration_ms:\n",
        "            # End segment at previous word boundary\n",
        "            if i > 0:\n",
        "                segment_end = words[i-1]['end']\n",
        "                segments.append((current_start, segment_end))\n",
        "                current_start = segment_end\n",
        "            else:\n",
        "                # First word itself exceeds duration, include it anyway\n",
        "                segment_end = word['end']\n",
        "                segments.append((current_start, segment_end))\n",
        "                current_start = segment_end\n",
        "\n",
        "    # Add final segment\n",
        "    if current_start < words[-1]['end']:\n",
        "        segments.append((current_start, words[-1]['end']))\n",
        "\n",
        "    # Export segments\n",
        "    print(f\"\\nCreating {len(segments)} segments...\")\n",
        "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "\n",
        "    for idx, (start, end) in enumerate(segments, 1):\n",
        "        start_ms = int(start * 1000)\n",
        "        end_ms = int(end * 1000)\n",
        "\n",
        "        segment_audio = audio[start_ms:end_ms]\n",
        "        output_path = os.path.join(output_dir, f\"{base_name}_segment_{idx:03d}.mp3\")\n",
        "\n",
        "        segment_audio.export(output_path, format=\"mp3\")\n",
        "        duration = (end - start)\n",
        "        print(f\"Segment {idx}: {duration:.2f}s ({start:.2f}s - {end:.2f}s) -> {output_path}\")\n",
        "\n",
        "    print(f\"\\nDone! Created {len(segments)} segments in '{output_dir}' directory\")\n",
        "    return segments\n",
        "\n",
        "\n",
        "def split_audio_aggressive(audio_path, max_duration=30, output_dir=\"segments\"):\n",
        "    \"\"\"\n",
        "    Alternative approach: More aggressive splitting for very fast speech.\n",
        "    Uses silence detection as fallback if word boundaries are too far apart.\n",
        "    \"\"\"\n",
        "    from pydub.silence import detect_nonsilent\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Loading Whisper model...\")\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    print(f\"Transcribing {audio_path}...\")\n",
        "    result = model.transcribe(audio_path, word_timestamps=True)\n",
        "\n",
        "    print(\"Loading audio file...\")\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "    # Extract words with timestamps\n",
        "    words = []\n",
        "    for segment in result['segments']:\n",
        "        if 'words' in segment:\n",
        "            words.extend(segment['words'])\n",
        "\n",
        "    if not words:\n",
        "        print(\"No words detected! Falling back to silence detection...\")\n",
        "        return split_on_silence_only(audio_path, max_duration, output_dir)\n",
        "\n",
        "    # Detect silence periods (as backup split points)\n",
        "    nonsilent_ranges = detect_nonsilent(audio, min_silence_len=100, silence_thresh=-40)\n",
        "\n",
        "    segments = []\n",
        "    current_start = 0\n",
        "    max_duration_ms = max_duration * 1000\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        word_end_ms = word['end'] * 1000\n",
        "        current_duration = word_end_ms - (current_start * 1000)\n",
        "\n",
        "        if current_duration >= max_duration_ms:\n",
        "            # Try to find a word boundary close to max_duration\n",
        "            target_time = current_start * 1000 + max_duration_ms\n",
        "\n",
        "            # Find nearest word end before target time\n",
        "            best_split = None\n",
        "            for j in range(i, -1, -1):\n",
        "                candidate_end = words[j]['end'] * 1000\n",
        "                if candidate_end <= target_time:\n",
        "                    best_split = words[j]['end']\n",
        "                    break\n",
        "\n",
        "            if best_split:\n",
        "                segments.append((current_start, best_split))\n",
        "                current_start = best_split\n",
        "            else:\n",
        "                # Use current word as split point\n",
        "                segments.append((current_start, word['end']))\n",
        "                current_start = word['end']\n",
        "\n",
        "    # Add final segment\n",
        "    if current_start < words[-1]['end']:\n",
        "        segments.append((current_start, words[-1]['end']))\n",
        "\n",
        "    # Export segments\n",
        "    print(f\"\\nCreating {len(segments)} segments...\")\n",
        "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
        "\n",
        "    for idx, (start, end) in enumerate(segments, 1):\n",
        "        start_ms = int(start * 1000)\n",
        "        end_ms = int(end * 1000)\n",
        "\n",
        "        segment_audio = audio[start_ms:end_ms]\n",
        "        output_path = os.path.join(output_dir, f\"{base_name}_segment_{idx:03d}.mp3\")\n",
        "\n",
        "        segment_audio.export(output_path, format=\"mp3\")\n",
        "        duration = (end - start)\n",
        "        print(f\"Segment {idx}: {duration:.2f}s -> {output_path}\")\n",
        "\n",
        "    print(f\"\\nDone! Created {len(segments)} segments\")\n",
        "    return segments\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # ============= MANUAL PATH SETTINGS =============\n",
        "    # Set your input audio file path here\n",
        "    audio_file = r\"/content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/August 2017 (1)/Konkani Prime News_100817.wav\"\n",
        "\n",
        "    # Set your output directory path here\n",
        "    output_directory = r\"/content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug\"\n",
        "\n",
        "    # Maximum duration per segment in seconds\n",
        "    max_segment_duration = 30\n",
        "    # ================================================\n",
        "\n",
        "    print(f\"Input audio: {audio_file}\")\n",
        "    print(f\"Output directory: {output_directory}\")\n",
        "    print(f\"Max segment duration: {max_segment_duration} seconds\\n\")\n",
        "\n",
        "    # Basic splitting (recommended)\n",
        "    segments = split_audio_on_word_boundaries(\n",
        "        audio_file,\n",
        "        max_duration=max_segment_duration,\n",
        "        output_dir=output_directory\n",
        "    )\n",
        "\n",
        "    # Or use aggressive splitting for very fast speech\n",
        "    # segments = split_audio_aggressive(\n",
        "    #     audio_file,\n",
        "    #     max_duration=max_segment_duration,\n",
        "    #     output_dir=output_directory\n",
        "    # )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "\n",
        "def transcribe_mp3_directory(input_dir, output_dir=None, model_size=\"medium\", language=None):\n",
        "    \"\"\"\n",
        "    Transcribe all MP3 files in a directory using Whisper model.\n",
        "\n",
        "    Args:\n",
        "        input_dir: Path to directory containing MP3 files\n",
        "        output_dir: Path to directory where transcripts will be saved (default: same as input_dir)\n",
        "        model_size: Whisper model size (default: \"medium\")\n",
        "        language: Language code (None for auto-detection, \"mr\" for Marathi, \"hi\" for Hindi)\n",
        "    \"\"\"\n",
        "\n",
        "    # Load Whisper model\n",
        "    print(f\"Loading Whisper {model_size} model...\")\n",
        "    model = whisper.load_model(model_size)\n",
        "\n",
        "    # Set up directories\n",
        "    input_path = Path(input_dir)\n",
        "    if output_dir is None:\n",
        "        output_path = input_path\n",
        "    else:\n",
        "        output_path = Path(output_dir)\n",
        "        output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Get all MP3 files\n",
        "    mp3_files = list(input_path.glob(\"*.mp3\"))\n",
        "\n",
        "    if not mp3_files:\n",
        "        print(f\"No MP3 files found in {input_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(mp3_files)} MP3 files to transcribe\")\n",
        "    print(f\"Language setting: {'Auto-detect' if language is None else language}\\n\")\n",
        "\n",
        "    # Transcribe each file\n",
        "    successful = 0\n",
        "    empty = 0\n",
        "\n",
        "    for i, mp3_file in enumerate(mp3_files, 1):\n",
        "        print(f\"[{i}/{len(mp3_files)}] Transcribing: {mp3_file.name}\")\n",
        "\n",
        "        try:\n",
        "            # Transcribe with additional options for better results\n",
        "            transcribe_options = {\n",
        "                \"task\": \"transcribe\",\n",
        "                \"fp16\": False,  # Use FP32 for better accuracy\n",
        "                \"temperature\": 0.0,  # Deterministic output\n",
        "                \"best_of\": 5,  # Try multiple decodings\n",
        "                \"beam_size\": 5,  # Better search\n",
        "            }\n",
        "\n",
        "            if language:\n",
        "                transcribe_options[\"language\"] = language\n",
        "\n",
        "            result = model.transcribe(str(mp3_file), **transcribe_options)\n",
        "\n",
        "            # Check if transcript is empty\n",
        "            transcript_text = result[\"text\"].strip()\n",
        "\n",
        "            if not transcript_text:\n",
        "                print(f\"⚠ Empty transcript (possibly silent audio)\")\n",
        "                empty += 1\n",
        "            else:\n",
        "                successful += 1\n",
        "                print(f\"✓ Detected language: {result.get('language', 'unknown')}\")\n",
        "                print(f\"  Text preview: {transcript_text[:100]}{'...' if len(transcript_text) > 100 else ''}\")\n",
        "\n",
        "            # Save transcript (even if empty, for tracking)\n",
        "            transcript_file = output_path / f\"{mp3_file.stem}_transcript.txt\"\n",
        "            with open(transcript_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(transcript_text)\n",
        "                f.write(f\"\\n\\n[Detected Language: {result.get('language', 'unknown')}]\")\n",
        "\n",
        "            print(f\"  Saved to: {transcript_file.name}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error transcribing {mp3_file.name}: {str(e)}\\n\")\n",
        "            continue\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"Transcription complete!\")\n",
        "    print(f\"Successful: {successful} | Empty: {empty} | Total: {len(mp3_files)}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # For Konkani audio, try these options:\n",
        "\n",
        "    # OPTION 1: Auto-detect language (recommended for Konkani)\n",
        "    # Whisper will try to detect the closest language\n",
        "    input_directory = \"/content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/audio segment/10 Aug\"\n",
        "    output_directory = \"/content/drive/MyDrive/Anju Project (1)/Audio Prudent media (1)/transcript segment/10 Aug\"\n",
        "\n",
        "    transcribe_mp3_directory(\n",
        "    input_dir=input_directory,\n",
        "    output_dir=output_directory,\n",
        "    model_size=\"large-v2\",\n",
        "    language=\"mr\"\n",
        ")\n",
        "\n",
        "\n",
        "    # OPTION 2: Try Hindi (closer to Konkani than Marathi)\n",
        "    # Uncomment below to try:\n",
        "    # transcribe_mp3_directory(\n",
        "    #     input_dir=input_directory,\n",
        "    #     output_dir=output_directory,\n",
        "    #     model_size=\"medium\",\n",
        "    #     language=\"hi\"  # Hindi\n",
        "    # )\n",
        "\n",
        "    # OPTION 3: Try Marathi (as originally requested)\n",
        "    # Uncomment below to try:\n",
        "    # transcribe_mp3_directory(\n",
        "    #     input_dir=input_directory,\n",
        "    #     output_dir=output_directory,\n",
        "    #     model_size=\"medium\",\n",
        "    #     language=\"mr\"  # Marathi\n",
        "    # )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RrMnKDwVHh0",
        "outputId": "7eff2bdc-cace-4020-a20d-73d42d015d2c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper large-v2 model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [00:36<00:00, 84.4MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15 MP3 files to transcribe\n",
            "Language setting: mr\n",
            "\n",
            "[1/15] Transcribing: Konkani Prime News_100817_segment_001.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: नमस्कार पोले प्रुडंड खोब्रोग टैंकर वालेंग न धर्बान गौय भर च वाटर टैंकर आचे ट्रांस्पोर्ट डिपाट्मेंट क...\n",
            "  Saved to: Konkani Prime News_100817_segment_001_transcript.txt\n",
            "\n",
            "[2/15] Transcribing: Konkani Prime News_100817_segment_002.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: पुर्रीकार खैंश सगल्यां ब्रश्ट मुख्यमुख्यमंत्री पुर्रीकार खैंश सगल्यां ब्रश्ट मुख्यमुख्यमंत्री पुर्री...\n",
            "  Saved to: Konkani Prime News_100817_segment_002_transcript.txt\n",
            "\n",
            "[3/15] Transcribing: Konkani Prime News_100817_segment_003.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: मिलिंदाची कार्ये गर्ध्यां ग्यों फातोडेर सांध बोरिये मिरें साथ वरांची वारी अनि भारतांट फुटसाला गेतले ...\n",
            "  Saved to: Konkani Prime News_100817_segment_003_transcript.txt\n",
            "\n",
            "[4/15] Transcribing: Konkani Prime News_100817_segment_004.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: कलसा बंडूरा परकल्बाचे काम कर्नाटकां केंड्राची पर्वान्गी नास्तन सुरू केला ही गजाल माधवी बच्याव अभियान...\n",
            "  Saved to: Konkani Prime News_100817_segment_004_transcript.txt\n",
            "\n",
            "[5/15] Transcribing: Konkani Prime News_100817_segment_005.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: माद काम जाल ले न अनि ते नेटान चल न मुण अभीयानान कोर्टा क्लियर केले कर्नाटकान असा अर्जक केला अनि केंड...\n",
            "  Saved to: Konkani Prime News_100817_segment_005_transcript.txt\n",
            "\n",
            "[6/15] Transcribing: Konkani Prime News_100817_segment_006.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: लोगांसा बारो प्रतिसाद मैटा मुन कॉंग्रेस्योच उमेद्वार किरीश चोड़ानकार मीडिया गडेनु लेलो एक्टिविस्ट आई...\n",
            "  Saved to: Konkani Prime News_100817_segment_006_transcript.txt\n",
            "\n",
            "[7/15] Transcribing: Konkani Prime News_100817_segment_007.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: पुर्ण विराम दिलो, विश्वी जीताँ फंड डिपोजिटोई केलो, वर्स 2007 विश्वी जीताँ आईरीशाक जीतो मारबाजी धंकी ...\n",
            "  Saved to: Konkani Prime News_100817_segment_007_transcript.txt\n",
            "\n",
            "[8/15] Transcribing: Konkani Prime News_100817_segment_008.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: तश्य सर्कुलरी हे पहली ख़ात्यां धालना इलेक्शन आचो कोड सुरू जाओचे पहली रेकुट्मेंट जाला तांचोछ अपउंड्मे...\n",
            "  Saved to: Konkani Prime News_100817_segment_008_transcript.txt\n",
            "\n",
            "[9/15] Transcribing: Konkani Prime News_100817_segment_009.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: संगर्ष समितीन पण्जेयून नवे कुल मुनकार दुरस्ति विदेयक जालपाच प्लान क्यालो खरो\n",
            "  Saved to: Konkani Prime News_100817_segment_009_transcript.txt\n",
            "\n",
            "[10/15] Transcribing: Konkani Prime News_100817_segment_010.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: माद इलेक्शन कोणाक परमिशन सार्क्यन अशिल्ल्यान प्लान फिसकाटलौं। अशिल्ले साथ आठ जानुज। करण जाले निधर्शन...\n",
            "  Saved to: Konkani Prime News_100817_segment_010_transcript.txt\n",
            "\n",
            "[11/15] Transcribing: Konkani Prime News_100817_segment_011.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: असले प्रकार बंद जाउंग जाये मुण गोवा मुमंस फोरम माकता फोरमान मढगावाच जागरती रहली कालली दाबोल केशाओ स्...\n",
            "  Saved to: Konkani Prime News_100817_segment_011_transcript.txt\n",
            "\n",
            "[12/15] Transcribing: Konkani Prime News_100817_segment_012.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: मुण शिक्षन संचालग गजानन भट प्रुडंटा कडेन उलेलो सिटिजन जर्नलिस्टाचे वीडियो वेल्यां प्रुडंटान हो प्रका...\n",
            "  Saved to: Konkani Prime News_100817_segment_012_transcript.txt\n",
            "\n",
            "[13/15] Transcribing: Konkani Prime News_100817_segment_013.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: गोईचो सादन सुविद तंका मानावल्यात मुर्गाउसो बीजेबीचो आमदार मिलिंद नाइकान आंग्वन पुराय केली वासकोते बो...\n",
            "  Saved to: Konkani Prime News_100817_segment_013_transcript.txt\n",
            "\n",
            "[14/15] Transcribing: Konkani Prime News_100817_segment_014.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: 43 मतानी जी किल्लो स्वतंद्रताय दीस्तेकलो आइकपाक याना उलोग कलना अश्या दिव्यांग लोकां खते राता साइन ले...\n",
            "  Saved to: Konkani Prime News_100817_segment_014_transcript.txt\n",
            "\n",
            "[15/15] Transcribing: Konkani Prime News_100817_segment_015.mp3\n",
            "✓ Detected language: mr\n",
            "  Text preview: फेस्बूक औनि प्रुडन्ट वेबसाइटी चेरी लाइव मेट आत। प्रुडन्ट आक फ़ोलोग करी थरावाद, पही थरावाद प्रुडन्ट, ...\n",
            "  Saved to: Konkani Prime News_100817_segment_015_transcript.txt\n",
            "\n",
            "============================================================\n",
            "Transcription complete!\n",
            "Successful: 15 | Empty: 0 | Total: 15\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}